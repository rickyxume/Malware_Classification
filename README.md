# Malware_Classification
数据来自Datawhale&amp;科大讯飞2021A.I.开发者大赛恶意软件分类

只有opcode词频和文件大小特征要怎么利用？

这里分享CV/NLP/ML三个方向的建模思路



### 传统ML

LR、SVM、树模型(LGB、XGB...)

由于有文件信息这种trick特征导致树模型可以特别准，结合降采样集成学习策略（如SPE）可以有效上分。
另外一种思路是ovo把这个任务当做是二分类来做，然后用MESA(一种比SPE强一点的meta learning方法)来做

（吐槽一句，为什么我复现不了baseline...随机数seed也看人品的么...，）

通过对词频和样本集的计算可以得到TFIDF特征，不过这个特征太弱了，加进去还会拉低ML模型效果，不如后面转换成文本再做表征。

表格类特征最有效的还是原始特征以及针对文件信息的一些目标统计编码，因为有大量的重复样本（可能是恶意软件的病毒式复制？），需要做一下降采样。

### CV方向

思路即词频转图像，然后用图像分类模型做分类。可以考虑的有CNN、ViT... 预训练同样奏效。

ViT可见[MalwareViT](https://github.com/rickyxume/MalwareViT)

传统的两层3x3卷积的CNN可以很好地在简单图像上（过）拟合，加入伪标签之后预测的和伪标签一模一样 =_=

MobileNetV2训练比ResNet50V2要快而且效果更好。


### NLP方向

思路即根据opcode词频复原出Asm文档，大概可以考虑文档分类的思路（或者考虑用P-tuning转化一下目标任务使之更贴近预训练模型的任务）。

可以用传统的Word2vec、Doc2vec、Glove、fasttext做embedding，经过meta-embedding（特征拼接，一般是Glove + Word2vec，本任务需要自己训练），后接LR、KNN、SVM、RF、MLP然后做stacking之类的融合

也可以深度学习BERT、Transformers、ULMFiT预训练再fine-turning，或者用 P-tuning，再或者用他们输出的特征和上面的embedding互补，加上静态统计特征一起训练。

**关于数据增强**：文本上常用的有简单随机删除、乱序、同义替换等，这里我仔细搜了每个opcode字段对应的意思，发现有一些词是等效的，因此我基于这些同义词做了一点数据增广的工作，首先对所有数据进行采样，只保留唯一的line_count_asm的样本，得到一个所有数据集的子集，再基于这个子集来做数据增广，对于0，1，2这几个数据少的类别我多做了几次增广，其他的类我只做一次随机同义替换，可能是我哪里操作不太对，使用数据增广后的模型在伪榜上测试普遍比之前差一点，由于时间精力有限也没有再实验了。

还有一种新的思路是利用simCSE这类对比学习方法在这个的少样本不平衡分类任务下做句子表征，simCSE中得到正样本对的dropout方法可以视作一种“弱”的数据增强方法，可效果一点也不弱，吊打BERT-flow之流，还有一种R-Drop策略也可以考虑使用，作为其他NN模型的高效正则方法，简单实用，效果类似，这部分可以看看苏剑林大神的博客，干货很多。


自己线下用线上0.988的结果当做伪榜做实验，发现Doc2vec得到300维的特征然后再跑LGB效果很不错，Glove因为环境问题没跑成功，有个PyTorch版本的但懒得折腾了，还有，用KNN也能很高分，结合SPE(降采样+集成学习)+模型融合(传统ML+树模型+视觉NN+文本NN)应该可以把这部分的分数提一点。

之前做的LGB+SPE可以到0.988，ViT可以到0.97475，方案一生成的简单图像用之前0.979的pseudo label全加进去一起训练CNN可以完全拟合数据达到0.979，（因为感觉准确率已经很高了就全都加进去了）猜测加上数据增强应该可以更鲁棒，图像部分的数据增强由于内存不太够没法跑完所有实验来验证想法。NLP方向，用fastai的AWD_LSTM预训练模型不加入line_count_asm信息的文本上fit两轮就上0.9了，用transformers库里预训练的BERT需要把line_count_asm加进文本来训练才可以，后面再fine-tuning, 只调了squeezeBERT，伪榜没到0.97，应该是我微调还不太熟练所以效果一般，再上大一点的模型不知道会不会有提升。

后续是，实验了一堆文本分类算法，用GPU跑了一整天的squeezebert，笔记本键盘还烫坏了...最后结论是：BERT微调还是干不过LGB，文本表征+树模型效果很好，用simCSE做文本表征可以一试，毕竟用doc2vec得到的特征向量再接上LGB这种树模型不调参随便跑一下在线下伪榜就可以很高分，包裹一层SPE降采样应该也能提分，最后再做一下三个领域的模型融合，根据这几种模型的差异性应该可以提升很多，不知道top1是怎么跑的可以这么高分？？？等他开源了。

累了，孩子要全身心准备考研了，有随缘整理代码。



代码后续上传，先把思路写出来（咕咕）
