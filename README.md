# Malware_Classification
数据来自Datawhale&amp;科大讯飞2021A.I.开发者大赛恶意软件分类

只有opcode词频和文件大小特征要怎么利用？

这里分享CV/NLP/ML三个方向的建模思路



### 传统ML

LR、SVM、树模型(LGB、XGB...)

由于有文件信息这种trick特征导致树模型可以特别准，结合降采样集成学习策略（如SPE）可以有效上分

### CV方向

思路即词频转图像，然后用图像分类模型做分类。可以考虑的有CNN、ViT... 预训练同样奏效。

ViT可见[MalwareViT](https://github.com/rickyxume/MalwareViT)

### NLP方向

思路即根据opcode词频复原出Asm文档，大概可以考虑序列分类、文档分类这两种思路。

可以用传统的Word2vec、Doc2vec后接LR、KNN

也可以深度学习BERT、Transformers预训练再fine-turning



做完上面几个之后可以做模型融合来提分。

目前我自己做的LGB+SPE可以到0.988，ViT可以到0.97475，用pseudo label加进去一起训练CNN可以完全拟合数据达到0.979，猜测加上数据增强应该可以更鲁棒，由于内存不太够没法跑完所有实验来验证想法，用fastai的AWD_LSTM预训练模型fit两轮就上0.9了，BERT和transformer大概0.8这样，再fine-tuning应该可以到很高的分数。

实验了一堆文本分类算法，跑了一整天的squeezebert，笔记本键盘还烫坏了...最后结论是：BERT微调还是干不过LGB，用simCSE可能可以一试，毕竟用doc2vec得到的特征向量再接上LGB这种树模型随便跑一下在线下伪榜就可以很高分，不过我没调参了，包裹一层我之前跑的SPE应该也能提分，最后再做一下三个领域的模型融合，根据这几种模型的差异性应该可以提升很多，不知道top1是怎么跑的可以这么高分？？？等他开源了。累了，孩子要全身心准备考研了。



代码后续上传，先把思路写出来
